# Kaggle Competition Music Genre Prediction & Feature engineering

**Проект выполнен в рамках соревнования на платформе Kaggle**
https://www.kaggle.com/competitions/music-genre-prediction-m125ds/leaderboard

## Задача проекта

Разработать ML модель, позволяющую классифицировать музыкальные произведения по жанрам

## Описание данных

* train.csv - информация (~20000) музыкальных треках, которые будут использоваться в качестве обучающих данных.  
* test.csv - информация (~5000) музыкальных треках, которые будут использоваться в качестве тестовых данных. Задача - предсказать значение 'music_genre' для каждого трека из этого датасета.    
* sample_submit.csv - файл предсказаний в правильном формате.  

instance_id - идентификатор трека в тестовом наборе.  
music_genre - Целевой признак. Для каждого трека нужно предсказать категориальное значение соответствующее музыкальному жанру трека.

**Описание данных**

* instance_id - уникальный идентификатор трека  
* track_name - название трека  
* acousticness - акустичность  
* danceability - танцевальность  
* duration_ms -продолжительность в милисекундах  
* energy - энергичность  
* instrumentalness - инструментальность  
* key - базовый ключ (нота) произведения  
* liveness - привлекательность  
* loudness - громкость  
* mode - указывает на модальность (мажорную или минорную) трека  
* speechiness - выразительность  
* tempo - темп  
* obtained_date - дата загрузки в сервис  
* valence - привлекательность произведения для пользователей сервиса  
* music_genre - музыкальный жанр  

## План исследования

1. Загрузка библиотек и файлов
2. Исследовательский анализ данных
    * Баланс классов
    * Анализ числовых признаков
    * Анализ категориальных признаков
    * Проверка значений на мультиколлинеарность
    * Проверка важности признаков (Mutual Information)
3. Обучение базовых моделей (Baseline)
4. Тюнинг моделей
    * Создание новых признаков
    * Выбор признаков для обучения моделей
    * Оптимизация моделей с использованием Pipeline и GridSearchCV
5. Проверка лучшей модели на адекватность с помощью константной модели DummyClassifier
6. Финальное предсказание на тестовой выборке
7. Проверка важности признаков (Feature Importances)
8. Вывод

## Решение

* Провели исследовательский анализ данных: проверили баланс классов music_genre, изучили числовые и категориальные признаки, выявили аномалии и удалили неинформативные колонки (instance_id, obtained_date, track_name, key, liveness, mode).

* Провели feature engineering: создали бинарные признаки на основе track_name, добавили длину названия трека и провели биннинг числовых признаков (duration_ms, tempo, energy, valence).

* Обучили три модели (LogisticRegression, RandomForestClassifier, CatBoostClassifier) с Pipeline и GridSearchCV для подбора гиперпараметров. Тюнинг моделей позволил улучшить результаты: лучшая модель — CatBoostClassifier — показала F1 Micro Score 0.494 (baseline — 0.469).

* DummyClassifier продемонстрировал F1 Micro Score 0.1408, подтверждая, что модель извлекает закономерности, а не угадывает случайно.

* Feature Importances показали наибольший вклад признаков instrumentalness, speechiness и danceability; наименьший — сгенерированные текстовые признаки (is_classical_like, has_feat, has_remix, has_remastered, has_live).

* После всех улучшений и предсказаний на тестовой выборке удалось повысить результат в соревновании Kaggle:

    * Было: публичная таблица — F1 micro = 0.4590, приватная — F1 micro = 0.4788
    * Стало: публичная таблица — F1 micro = 0.4935, приватная — F1 micro = 0.5012

Таким образом, комбинация feature engineering, тюнинга гиперпараметров и оценки важности признаков позволила улучшить качество модели и достичь более высоких значений F1 Micro на тестовой выборке.

## Используемые библиотеки и инструменты

Pandas, NumPy, Matplotlib, Seaborn, Sklearn, Phik, Сollections, Feature_engine


